{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Biology/index.html"
      ],
      "metadata": {
        "id": "JtPtWKO47CJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Today, we officially begin our Neural Networks and Deep Learning Course as introduced here. We’ll begin with a solid introduction to the concept of artificial neurons (perceptrons) in neural networks.\n",
        "\n",
        "Artificial neurons (also called Perceptrons, Units or Nodes) are the simplest elements or building blocks in a neural network. They are inspired by biological neurons that are found in the human brain.\n",
        "\n",
        "we’ll discuss how perceptrons are inspired by biological neurons, draw the structure of a perceptron, discuss the two mathematical functions inside a perceptron and finally, we’ll perform some calculations inside a perceptron."
      ],
      "metadata": {
        "id": "wfsynk6n7yKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Applications of neural networks**\n",
        "1. **Character Recognition** - The idea of character recognition has become very important as handheld devices like the Palm Pilot are becoming increasingly popular. Neural networks can be used to recognize handwritten characters.\n",
        "\n",
        "2. **Image Compression** - Neural networks can receive and process vast amounts of information at once, making them useful in image compression. With the Internet explosion and more sites using more images on their sites, using neural networks for image compression is worth a look.\n",
        "\n",
        "3. **Stock Market Prediction** - The day-to-day business of the stock market is extremely complicated. Many factors weigh in whether a given stock will go up or down on any given day. Since neural networks can examine a lot of information quickly and sort it all out, they can be used to predict stock prices.\n"
      ],
      "metadata": {
        "id": "Te2HhWOv7mc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**How are perceptrons inspired by biological neurons?**\n",
        "It is worth discussing how artificial neurons (perceptrons) are inspired by biological neurons. You can consider an artificial neuron as a mathematical model inspired by a biological neuron."
      ],
      "metadata": {
        "id": "5rL0EQdg8D5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://towardsdatascience.com/wp-content/uploads/2021/12/1hkYlTODpjJgo32DoCOWN5w.png\">"
      ],
      "metadata": {
        "id": "e_kBoAb17iiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. A biological neuron receives its input signals from other neurons through dendrites __ (small fibers). Likewise, a perceptron receives its data from other perceptrons through input neurons that take numbers.\n",
        "\n",
        "2. The connection points between dendrites and ** biological neurons are called synapses. Likewise, the connections points between inputs and perceptrons are called weight**s. They measure the importance level of each input.\n",
        "\n",
        "3. In a biological neuron, the nucleus produces an output signal based on the signals provided by dendrites. Likewise, the nucleus (colored in blue) in a perceptron performs some calculations based on the input values and produces an output.\n",
        "\n",
        "4. In a biological neuron, the output signal is carried away by the axon. Likewise, the axon in a perceptron is the output value which will be the input for the next perceptrons."
      ],
      "metadata": {
        "id": "DN6qu-sW8fG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**The structure of a perceptron**\n",
        "The following image shows a detailed structure of a perceptron.\n",
        "<img src=\"https://towardsdatascience.com/wp-content/uploads/2021/12/1_1K2AV2rTjY3EWSJSvmPDQ.png\">\n",
        "\n",
        "A perceptron takes the inputs, x1, x2, …, xn, multiplies them by weights, w1, w2, …, wn and adds the bias term, b, then **computes the linear function z on which an activation function f is applied to get the output,** y."
      ],
      "metadata": {
        "id": "PP04D59S9IkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*2qzdr2H5dBwomr1JfY5WfQ.png\">"
      ],
      "metadata": {
        "id": "JY3tU9tL9Tc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Inside a perceptron**\n",
        "A perceptron usually consists of two mathematical functions.\n",
        "\n",
        "1. Perceptron’s linear function\n",
        "This is also called the linear component of the perceptron. It is denoted by z. Its output is the weighted sum of the inputs plus bias unit and can be calculated as follows.\n",
        "<img src=\"https://towardsdatascience.com/wp-content/uploads/2021/12/1RoJ9uRjvYqcG2L3RICMtEg.png\">\n",
        "\n",
        "1. The x1, x2, …, xn are inputs that take numerical values. There can be several (finite) inputs for a single neuron. They can be raw input data or outputs of the other perceptrons.\n",
        "\n",
        "2. The w1, w2, …, wn are weights that take numerical values and control the level of importance of each input. The higher the value, the more important the input.w1.x1 + w2.x2 + … + wn.xn is called the weighted sum of inputs.\n",
        "\n",
        "3. The b is called the bias term or bias unit that also takes a numerical value. It is added to the weighted sum of inputs. The purpose of including a bias term is to shift the activation function of each perceptron to not get a zero value. In other words, if all x1, x2, …, xn inputs are 0, the z is equal to the value of bias.\n",
        "\n",
        "4. The weights and biases are called the parameters in a neural network model. The optimal values for those parameters are found during the learning (training) process of the neural network.\n",
        "\n",
        "You can also think of the above z function as a linear regression model in which weights are known as coefficients and the bias term is known as the intercept. This is just the terminology used to identify the same thing in different contexts."
      ],
      "metadata": {
        "id": "nmHHwKAL94x1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdPy0MbbQM6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}